{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case 1 - Building the Model\n",
    "\n",
    "**Importing Relevant Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('data/Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "\n",
    "npz = np.load('data/Audiobooks_data_validation.npz')\n",
    "\n",
    "validation_inputs = npz['inputs'].astype(np.float)\n",
    "validation_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "\n",
    "npz = np.load('data/Audiobooks_data_test.npz')\n",
    "\n",
    "test_inputs = npz['inputs'].astype(np.float)\n",
    "test_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Outline optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 1s - loss: 0.5582 - accuracy: 0.6938 - val_loss: 0.4785 - val_accuracy: 0.7181\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.4475 - accuracy: 0.7821 - val_loss: 0.4173 - val_accuracy: 0.7897\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.4024 - accuracy: 0.8005 - val_loss: 0.3889 - val_accuracy: 0.8031\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.3815 - accuracy: 0.7935 - val_loss: 0.3843 - val_accuracy: 0.7919\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.3706 - accuracy: 0.7977 - val_loss: 0.3681 - val_accuracy: 0.8098\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.3587 - accuracy: 0.8066 - val_loss: 0.3620 - val_accuracy: 0.7919\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.3531 - accuracy: 0.8125 - val_loss: 0.3734 - val_accuracy: 0.7852\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.3488 - accuracy: 0.8175 - val_loss: 0.3562 - val_accuracy: 0.8166\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.3474 - accuracy: 0.8106 - val_loss: 0.3571 - val_accuracy: 0.8188\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.3455 - accuracy: 0.8117 - val_loss: 0.3491 - val_accuracy: 0.8098\n",
      "Epoch 11/100\n",
      "3579/3579 - 0s - loss: 0.3422 - accuracy: 0.8167 - val_loss: 0.3431 - val_accuracy: 0.8166\n",
      "Epoch 12/100\n",
      "3579/3579 - 0s - loss: 0.3386 - accuracy: 0.8134 - val_loss: 0.3488 - val_accuracy: 0.8009\n",
      "Epoch 13/100\n",
      "3579/3579 - 0s - loss: 0.3399 - accuracy: 0.8159 - val_loss: 0.3442 - val_accuracy: 0.8277\n",
      "Epoch 14/100\n",
      "3579/3579 - 0s - loss: 0.3346 - accuracy: 0.8195 - val_loss: 0.3430 - val_accuracy: 0.8255\n",
      "Epoch 15/100\n",
      "3579/3579 - 0s - loss: 0.3398 - accuracy: 0.8083 - val_loss: 0.3506 - val_accuracy: 0.8054\n",
      "Epoch 16/100\n",
      "3579/3579 - 0s - loss: 0.3289 - accuracy: 0.8206 - val_loss: 0.3438 - val_accuracy: 0.8210\n",
      "Epoch 17/100\n",
      "3579/3579 - 0s - loss: 0.3287 - accuracy: 0.8229 - val_loss: 0.3368 - val_accuracy: 0.8277\n",
      "Epoch 18/100\n",
      "3579/3579 - 0s - loss: 0.3273 - accuracy: 0.8243 - val_loss: 0.3354 - val_accuracy: 0.8233\n",
      "Epoch 19/100\n",
      "3579/3579 - 0s - loss: 0.3252 - accuracy: 0.8215 - val_loss: 0.3379 - val_accuracy: 0.8210\n",
      "Epoch 20/100\n",
      "3579/3579 - 0s - loss: 0.3251 - accuracy: 0.8287 - val_loss: 0.3410 - val_accuracy: 0.8255\n",
      "Epoch 21/100\n",
      "3579/3579 - 0s - loss: 0.3239 - accuracy: 0.8231 - val_loss: 0.3357 - val_accuracy: 0.8143\n",
      "Epoch 22/100\n",
      "3579/3579 - 0s - loss: 0.3278 - accuracy: 0.8167 - val_loss: 0.3390 - val_accuracy: 0.8098\n",
      "Epoch 23/100\n",
      "3579/3579 - 0s - loss: 0.3230 - accuracy: 0.8201 - val_loss: 0.3439 - val_accuracy: 0.8210\n",
      "Epoch 24/100\n",
      "3579/3579 - 0s - loss: 0.3256 - accuracy: 0.8175 - val_loss: 0.3342 - val_accuracy: 0.8166\n",
      "Epoch 25/100\n",
      "3579/3579 - 0s - loss: 0.3203 - accuracy: 0.8279 - val_loss: 0.3338 - val_accuracy: 0.8166\n",
      "Epoch 26/100\n",
      "3579/3579 - 0s - loss: 0.3197 - accuracy: 0.8268 - val_loss: 0.3304 - val_accuracy: 0.8255\n",
      "Epoch 27/100\n",
      "3579/3579 - 0s - loss: 0.3197 - accuracy: 0.8259 - val_loss: 0.3329 - val_accuracy: 0.8277\n",
      "Epoch 28/100\n",
      "3579/3579 - 0s - loss: 0.3182 - accuracy: 0.8237 - val_loss: 0.3407 - val_accuracy: 0.8300\n",
      "Epoch 29/100\n",
      "3579/3579 - 0s - loss: 0.3182 - accuracy: 0.8290 - val_loss: 0.3367 - val_accuracy: 0.8255\n",
      "Epoch 30/100\n",
      "3579/3579 - 0s - loss: 0.3171 - accuracy: 0.8220 - val_loss: 0.3337 - val_accuracy: 0.8166\n",
      "Epoch 31/100\n",
      "3579/3579 - 0s - loss: 0.3180 - accuracy: 0.8243 - val_loss: 0.3335 - val_accuracy: 0.8277\n",
      "Epoch 32/100\n",
      "3579/3579 - 0s - loss: 0.3159 - accuracy: 0.8279 - val_loss: 0.3310 - val_accuracy: 0.8255\n",
      "Epoch 33/100\n",
      "3579/3579 - 0s - loss: 0.3171 - accuracy: 0.8240 - val_loss: 0.3302 - val_accuracy: 0.8188\n",
      "Epoch 34/100\n",
      "3579/3579 - 0s - loss: 0.3164 - accuracy: 0.8243 - val_loss: 0.3323 - val_accuracy: 0.8121\n",
      "Epoch 35/100\n",
      "3579/3579 - 0s - loss: 0.3179 - accuracy: 0.8198 - val_loss: 0.3454 - val_accuracy: 0.8233\n",
      "Epoch 36/100\n",
      "3579/3579 - 0s - loss: 0.3156 - accuracy: 0.8298 - val_loss: 0.3302 - val_accuracy: 0.8300\n",
      "Epoch 37/100\n",
      "3579/3579 - 0s - loss: 0.3147 - accuracy: 0.8262 - val_loss: 0.3381 - val_accuracy: 0.8188\n",
      "Epoch 38/100\n",
      "3579/3579 - 0s - loss: 0.3164 - accuracy: 0.8284 - val_loss: 0.3347 - val_accuracy: 0.8300\n",
      "Epoch 39/100\n",
      "3579/3579 - 0s - loss: 0.3149 - accuracy: 0.8254 - val_loss: 0.3398 - val_accuracy: 0.7942\n",
      "Epoch 40/100\n",
      "3579/3579 - 0s - loss: 0.3184 - accuracy: 0.8293 - val_loss: 0.3457 - val_accuracy: 0.8233\n",
      "Epoch 41/100\n",
      "3579/3579 - 0s - loss: 0.3130 - accuracy: 0.8293 - val_loss: 0.3304 - val_accuracy: 0.8277\n",
      "Epoch 42/100\n",
      "3579/3579 - 0s - loss: 0.3109 - accuracy: 0.8321 - val_loss: 0.3285 - val_accuracy: 0.8233\n",
      "Epoch 43/100\n",
      "3579/3579 - 0s - loss: 0.3115 - accuracy: 0.8310 - val_loss: 0.3299 - val_accuracy: 0.8188\n",
      "Epoch 44/100\n",
      "3579/3579 - 0s - loss: 0.3147 - accuracy: 0.8265 - val_loss: 0.3349 - val_accuracy: 0.8255\n",
      "Epoch 45/100\n",
      "3579/3579 - 0s - loss: 0.3136 - accuracy: 0.8259 - val_loss: 0.3271 - val_accuracy: 0.8076\n",
      "Epoch 46/100\n",
      "3579/3579 - 0s - loss: 0.3126 - accuracy: 0.8268 - val_loss: 0.3309 - val_accuracy: 0.8210\n",
      "Epoch 47/100\n",
      "3579/3579 - 0s - loss: 0.3138 - accuracy: 0.8284 - val_loss: 0.3384 - val_accuracy: 0.8210\n",
      "Epoch 48/100\n",
      "3579/3579 - 0s - loss: 0.3159 - accuracy: 0.8164 - val_loss: 0.3349 - val_accuracy: 0.8277\n",
      "Epoch 49/100\n",
      "3579/3579 - 0s - loss: 0.3149 - accuracy: 0.8270 - val_loss: 0.3356 - val_accuracy: 0.8188\n",
      "Epoch 50/100\n",
      "3579/3579 - 0s - loss: 0.3125 - accuracy: 0.8287 - val_loss: 0.3333 - val_accuracy: 0.8322\n",
      "Epoch 51/100\n",
      "3579/3579 - 0s - loss: 0.3125 - accuracy: 0.8259 - val_loss: 0.3488 - val_accuracy: 0.7875\n",
      "Epoch 52/100\n",
      "3579/3579 - 0s - loss: 0.3117 - accuracy: 0.8318 - val_loss: 0.3260 - val_accuracy: 0.8300\n",
      "Epoch 53/100\n",
      "3579/3579 - 0s - loss: 0.3125 - accuracy: 0.8307 - val_loss: 0.3326 - val_accuracy: 0.8233\n",
      "Epoch 54/100\n",
      "3579/3579 - 0s - loss: 0.3102 - accuracy: 0.8268 - val_loss: 0.3294 - val_accuracy: 0.8300\n",
      "Epoch 55/100\n",
      "3579/3579 - 0s - loss: 0.3109 - accuracy: 0.8290 - val_loss: 0.3288 - val_accuracy: 0.8210\n",
      "Epoch 56/100\n",
      "3579/3579 - 0s - loss: 0.3088 - accuracy: 0.8290 - val_loss: 0.3297 - val_accuracy: 0.8233\n",
      "Epoch 57/100\n",
      "3579/3579 - 0s - loss: 0.3082 - accuracy: 0.8315 - val_loss: 0.3319 - val_accuracy: 0.8255\n",
      "Epoch 58/100\n",
      "3579/3579 - 0s - loss: 0.3111 - accuracy: 0.8273 - val_loss: 0.3280 - val_accuracy: 0.8300\n",
      "Epoch 59/100\n",
      "3579/3579 - 0s - loss: 0.3078 - accuracy: 0.8293 - val_loss: 0.3263 - val_accuracy: 0.8210\n",
      "Epoch 60/100\n",
      "3579/3579 - 0s - loss: 0.3125 - accuracy: 0.8265 - val_loss: 0.3335 - val_accuracy: 0.7987\n",
      "Epoch 61/100\n",
      "3579/3579 - 0s - loss: 0.3138 - accuracy: 0.8265 - val_loss: 0.3340 - val_accuracy: 0.8233\n",
      "Epoch 62/100\n",
      "3579/3579 - 0s - loss: 0.3064 - accuracy: 0.8324 - val_loss: 0.3251 - val_accuracy: 0.8143\n",
      "Epoch 63/100\n",
      "3579/3579 - 0s - loss: 0.3090 - accuracy: 0.8284 - val_loss: 0.3283 - val_accuracy: 0.8188\n",
      "Epoch 64/100\n",
      "3579/3579 - 0s - loss: 0.3093 - accuracy: 0.8284 - val_loss: 0.3271 - val_accuracy: 0.8277\n",
      "Epoch 65/100\n",
      "3579/3579 - 0s - loss: 0.3077 - accuracy: 0.8273 - val_loss: 0.3263 - val_accuracy: 0.8255\n",
      "Epoch 66/100\n",
      "3579/3579 - 0s - loss: 0.3055 - accuracy: 0.8273 - val_loss: 0.3302 - val_accuracy: 0.8210\n",
      "Epoch 67/100\n",
      "3579/3579 - 0s - loss: 0.3086 - accuracy: 0.8326 - val_loss: 0.3294 - val_accuracy: 0.8188\n",
      "Epoch 68/100\n",
      "3579/3579 - 0s - loss: 0.3119 - accuracy: 0.8265 - val_loss: 0.3293 - val_accuracy: 0.8233\n",
      "Epoch 69/100\n",
      "3579/3579 - 0s - loss: 0.3080 - accuracy: 0.8324 - val_loss: 0.3364 - val_accuracy: 0.8255\n",
      "Epoch 70/100\n",
      "3579/3579 - 0s - loss: 0.3134 - accuracy: 0.8256 - val_loss: 0.3328 - val_accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "3579/3579 - 0s - loss: 0.3091 - accuracy: 0.8254 - val_loss: 0.3308 - val_accuracy: 0.8210\n",
      "Epoch 72/100\n",
      "3579/3579 - 0s - loss: 0.3093 - accuracy: 0.8276 - val_loss: 0.3316 - val_accuracy: 0.8121\n",
      "Epoch 73/100\n",
      "3579/3579 - 0s - loss: 0.3132 - accuracy: 0.8223 - val_loss: 0.3348 - val_accuracy: 0.7987\n",
      "Epoch 74/100\n",
      "3579/3579 - 0s - loss: 0.3117 - accuracy: 0.8273 - val_loss: 0.3256 - val_accuracy: 0.8166\n",
      "Epoch 75/100\n",
      "3579/3579 - 0s - loss: 0.3070 - accuracy: 0.8315 - val_loss: 0.3350 - val_accuracy: 0.7942\n",
      "Epoch 76/100\n",
      "3579/3579 - 0s - loss: 0.3047 - accuracy: 0.8312 - val_loss: 0.3299 - val_accuracy: 0.8322\n",
      "Epoch 77/100\n",
      "3579/3579 - 0s - loss: 0.3079 - accuracy: 0.8304 - val_loss: 0.3257 - val_accuracy: 0.8210\n",
      "Epoch 78/100\n",
      "3579/3579 - 0s - loss: 0.3070 - accuracy: 0.8307 - val_loss: 0.3359 - val_accuracy: 0.8255\n",
      "Epoch 79/100\n",
      "3579/3579 - 0s - loss: 0.3056 - accuracy: 0.8318 - val_loss: 0.3328 - val_accuracy: 0.8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "3579/3579 - 0s - loss: 0.3072 - accuracy: 0.8279 - val_loss: 0.3307 - val_accuracy: 0.8188\n",
      "Epoch 81/100\n",
      "3579/3579 - 0s - loss: 0.3076 - accuracy: 0.8301 - val_loss: 0.3273 - val_accuracy: 0.8277\n",
      "Epoch 82/100\n",
      "3579/3579 - 0s - loss: 0.3077 - accuracy: 0.8256 - val_loss: 0.3303 - val_accuracy: 0.8255\n",
      "Epoch 83/100\n",
      "3579/3579 - 0s - loss: 0.3054 - accuracy: 0.8284 - val_loss: 0.3284 - val_accuracy: 0.8098\n",
      "Epoch 84/100\n",
      "3579/3579 - 0s - loss: 0.3063 - accuracy: 0.8304 - val_loss: 0.3329 - val_accuracy: 0.8143\n",
      "Epoch 85/100\n",
      "3579/3579 - 0s - loss: 0.3104 - accuracy: 0.8282 - val_loss: 0.3261 - val_accuracy: 0.8255\n",
      "Epoch 86/100\n",
      "3579/3579 - 0s - loss: 0.3072 - accuracy: 0.8304 - val_loss: 0.3252 - val_accuracy: 0.8255\n",
      "Epoch 87/100\n",
      "3579/3579 - 0s - loss: 0.3074 - accuracy: 0.8276 - val_loss: 0.3340 - val_accuracy: 0.8322\n",
      "Epoch 88/100\n",
      "3579/3579 - 0s - loss: 0.3063 - accuracy: 0.8329 - val_loss: 0.3285 - val_accuracy: 0.8210\n",
      "Epoch 89/100\n",
      "3579/3579 - 0s - loss: 0.3084 - accuracy: 0.8279 - val_loss: 0.3362 - val_accuracy: 0.8233\n",
      "Epoch 90/100\n",
      "3579/3579 - 0s - loss: 0.3044 - accuracy: 0.8293 - val_loss: 0.3301 - val_accuracy: 0.8255\n",
      "Epoch 91/100\n",
      "3579/3579 - 0s - loss: 0.3031 - accuracy: 0.8312 - val_loss: 0.3382 - val_accuracy: 0.8322\n",
      "Epoch 92/100\n",
      "3579/3579 - 0s - loss: 0.3096 - accuracy: 0.8265 - val_loss: 0.3306 - val_accuracy: 0.8233\n",
      "Epoch 93/100\n",
      "3579/3579 - 0s - loss: 0.3066 - accuracy: 0.8270 - val_loss: 0.3281 - val_accuracy: 0.8098\n",
      "Epoch 94/100\n",
      "3579/3579 - 0s - loss: 0.3038 - accuracy: 0.8284 - val_loss: 0.3295 - val_accuracy: 0.8322\n",
      "Epoch 95/100\n",
      "3579/3579 - 0s - loss: 0.3035 - accuracy: 0.8321 - val_loss: 0.3320 - val_accuracy: 0.8121\n",
      "Epoch 96/100\n",
      "3579/3579 - 0s - loss: 0.3042 - accuracy: 0.8340 - val_loss: 0.3275 - val_accuracy: 0.8121\n",
      "Epoch 97/100\n",
      "3579/3579 - 0s - loss: 0.3031 - accuracy: 0.8335 - val_loss: 0.3247 - val_accuracy: 0.8210\n",
      "Epoch 98/100\n",
      "3579/3579 - 0s - loss: 0.3029 - accuracy: 0.8385 - val_loss: 0.3309 - val_accuracy: 0.8233\n",
      "Epoch 99/100\n",
      "3579/3579 - 0s - loss: 0.3045 - accuracy: 0.8315 - val_loss: 0.3265 - val_accuracy: 0.8277\n",
      "Epoch 100/100\n",
      "3579/3579 - 0s - loss: 0.3025 - accuracy: 0.8324 - val_loss: 0.3345 - val_accuracy: 0.8210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16ecddb8b70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50 #neurons in each layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size =  100\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "model.fit(train_inputs,\n",
    "         train_targets,\n",
    "         batch_size = batch_size,\n",
    "         epochs = max_epochs,\n",
    "         validation_data = (validation_inputs, validation_targets),\n",
    "         verbose = 2 \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Earling Stopping\n",
    "[class EarlyStopping: Stop training when a monitored quantity has stopped improving.](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  tf.keras.callbacks.EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 1s - loss: 0.6014 - accuracy: 0.6745 - val_loss: 0.5110 - val_accuracy: 0.7562\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.4760 - accuracy: 0.7608 - val_loss: 0.4312 - val_accuracy: 0.7919\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.4204 - accuracy: 0.7754 - val_loss: 0.4000 - val_accuracy: 0.8054\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.3925 - accuracy: 0.7907 - val_loss: 0.3803 - val_accuracy: 0.7763\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.3781 - accuracy: 0.7952 - val_loss: 0.3671 - val_accuracy: 0.8188\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.3667 - accuracy: 0.8025 - val_loss: 0.3641 - val_accuracy: 0.8076\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.3588 - accuracy: 0.8080 - val_loss: 0.3597 - val_accuracy: 0.8121\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.3577 - accuracy: 0.8047 - val_loss: 0.3604 - val_accuracy: 0.8098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16ed1ed1358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as previows section\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "\n",
    "#Same as previows section\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# -- Adding EARLY STOPPING --\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs = max_epochs,\n",
    "          callbacks = [early_stopping], #early stopping\n",
    "          validation_data = (validation_inputs, validation_targets),\n",
    "          verbose = 2 \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping with `Patience`\n",
    "- Allow few more epochs after reaching early sttoping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 1s - loss: 0.5684 - accuracy: 0.6745 - val_loss: 0.4883 - val_accuracy: 0.7204\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.4602 - accuracy: 0.7667 - val_loss: 0.4274 - val_accuracy: 0.7606\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.4142 - accuracy: 0.7877 - val_loss: 0.3997 - val_accuracy: 0.7740\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.3913 - accuracy: 0.7952 - val_loss: 0.3896 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.3759 - accuracy: 0.8002 - val_loss: 0.3793 - val_accuracy: 0.8098\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.3660 - accuracy: 0.8092 - val_loss: 0.3704 - val_accuracy: 0.8121\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.3568 - accuracy: 0.8125 - val_loss: 0.3687 - val_accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.3528 - accuracy: 0.8139 - val_loss: 0.3594 - val_accuracy: 0.8054\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.3497 - accuracy: 0.8122 - val_loss: 0.3640 - val_accuracy: 0.8143\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.3489 - accuracy: 0.8128 - val_loss: 0.3641 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16ed3691128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as previows section\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "\n",
    "#Same as previows section\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# -- Adding EARLY STOPPING --\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs = max_epochs,\n",
    "          callbacks = [early_stopping],\n",
    "          validation_data = (validation_inputs, validation_targets),\n",
    "          verbose = 2 \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "448/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 401us/sample - loss: 0.3096 - accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy =  model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.35 \n",
      "Test accuracy 81.03%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {:.2f} \\nTest accuracy {:.2f}%\".format(test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "Excellent!\n",
    "Test accuracy is slightly lower than validation accuracy\n",
    "The model determined 80% accurace in the convertion rate of the customers.\n",
    "Further preprocessing can considered in order to improve the model regarding to preprocessing techniques available and tunning the model through hyperparamenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
